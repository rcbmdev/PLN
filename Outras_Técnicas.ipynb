{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ainda pior que a convicção do não e a incerteza do talvez é a desilusão de um quase. É o quase que me incomoda, que me entristece, que me mata trazendo tudo que poderia ter sido e não foi. Quem quase ganhou ainda joga, quem quase passou ainda estuda, quem quase morreu está vivo, quem quase amou não amou. Basta pensar nas oportunidades que escaparam pelos dedos, nas chances que se perdem por medo, nas ideias que nunca sairão do papel por essa maldita mania de viver no outono. \n"
     ]
    }
   ],
   "source": [
    "# Fazendo a leitura de um arquivo se texto\n",
    "with open(os.path.join(\"data\", \"frases.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ainda pior que a convicção do não e a incerteza do talvez é a desilusão de um quase.', 'É o quase que me incomoda, que me entristece, que me mata trazendo tudo que poderia ter sido e não foi.', 'Quem quase ganhou ainda joga, quem quase passou ainda estuda, quem quase morreu está vivo, quem quase amou não amou.', 'Basta pensar nas oportunidades que escaparam pelos dedos, nas chances que se perdem por medo, nas ideias que nunca sairão do papel por essa maldita mania de viver no outono.']\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = sent_tokenize(text)\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ainda', 'pior', 'que', 'a', 'convicção', 'do', 'não', 'e', 'a', 'incerteza', 'do', 'talvez', 'é', 'a', 'desilusão', 'de', 'um', 'quase', '.', 'É', 'o', 'quase', 'que', 'me', 'incomoda', ',', 'que', 'me', 'entristece', ',', 'que', 'me', 'mata', 'trazendo', 'tudo', 'que', 'poderia', 'ter', 'sido', 'e', 'não', 'foi', '.', 'Quem', 'quase', 'ganhou', 'ainda', 'joga', ',', 'quem', 'quase', 'passou', 'ainda', 'estuda', ',', 'quem', 'quase', 'morreu', 'está', 'vivo', ',', 'quem', 'quase', 'amou', 'não', 'amou', '.', 'Basta', 'pensar', 'nas', 'oportunidades', 'que', 'escaparam', 'pelos', 'dedos', ',', 'nas', 'chances', 'que', 'se', 'perdem', 'por', 'medo', ',', 'nas', 'ideias', 'que', 'nunca', 'sairão', 'do', 'papel', 'por', 'essa', 'maldita', 'mania', 'de', 'viver', 'no', 'outono', '.']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'estamos',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivéramos',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estávamos',\n",
       " 'estão',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'fui',\n",
       " 'fôramos',\n",
       " 'fôssemos',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'havemos',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houveram',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houvermos',\n",
       " 'houverá',\n",
       " 'houverão',\n",
       " 'houveríamos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvéramos',\n",
       " 'houvéssemos',\n",
       " 'há',\n",
       " 'hão',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'não',\n",
       " 'nós',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'são',\n",
       " 'só',\n",
       " 'também',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivéramos',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'tém',\n",
       " 'tínhamos',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'à',\n",
       " 'às',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_portugues = set(stopwords.words('portuguese'))\n",
    "stop_portugues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ainda\n",
      "pior\n",
      "convicção\n",
      "incerteza\n",
      "talvez\n",
      "é\n",
      "desilusão\n",
      "quase\n",
      ".\n",
      "É\n",
      "quase\n",
      "incomoda\n",
      ",\n",
      "entristece\n",
      ",\n",
      "mata\n",
      "trazendo\n",
      "tudo\n",
      "poderia\n",
      "ter\n",
      "sido\n",
      ".\n",
      "Quem\n",
      "quase\n",
      "ganhou\n",
      "ainda\n",
      "joga\n",
      ",\n",
      "quase\n",
      "passou\n",
      "ainda\n",
      "estuda\n",
      ",\n",
      "quase\n",
      "morreu\n",
      "vivo\n",
      ",\n",
      "quase\n",
      "amou\n",
      "amou\n",
      ".\n",
      "Basta\n",
      "pensar\n",
      "oportunidades\n",
      "escaparam\n",
      "dedos\n",
      ",\n",
      "chances\n",
      "perdem\n",
      "medo\n",
      ",\n",
      "ideias\n",
      "nunca\n",
      "sairão\n",
      "papel\n",
      "maldita\n",
      "mania\n",
      "viver\n",
      "outono\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for palavra in word_tokens:\n",
    "    if palavra not in stop_portugues:\n",
    "        print(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ainda', 'pior', 'convicção', 'incerteza', 'talvez', 'é', 'desilusão', 'quase', '.', 'É', 'quase', 'incomoda', ',', 'entristece', ',', 'mata', 'trazendo', 'tudo', 'poderia', 'ter', 'sido', '.', 'Quem', 'quase', 'ganhou', 'ainda', 'joga', ',', 'quase', 'passou', 'ainda', 'estuda', ',', 'quase', 'morreu', 'vivo', ',', 'quase', 'amou', 'amou', '.', 'Basta', 'pensar', 'oportunidades', 'escaparam', 'dedos', ',', 'chances', 'perdem', 'medo', ',', 'ideias', 'nunca', 'sairão', 'papel', 'maldita', 'mania', 'viver', 'outono', '.']\n"
     ]
    }
   ],
   "source": [
    "print([palavra for palavra in word_tokens if palavra not in stop_portugues])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequência de Distribuição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(word_tokens)\n",
    "\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot word cloud\n",
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(text)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image to np.array\n",
    "mask = np.array(Image.open('upvote.png'))\n",
    "# Generate wordcloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', colormap='Set2', collocations=False, stopwords = STOPWORDS, mask=mask).generate(text)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wordcloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='navy', colormap='rainbow', collocations=False, stopwords = STOPWORDS, mask=mask).generate(text)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
